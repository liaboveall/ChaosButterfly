"""
ChaosButterfly v2.0 - é«˜çº§åŠ å¯†ç³»ç»Ÿ
æ”¯æŒå¤šç§åŠ å¯†æ¨¡å¼å’Œå¹¶è¡Œå¤„ç†
"""

import numpy as np
import cv2
import time
import os
import logging
from typing import Tuple, Optional, Union, Dict, Any
from dataclasses import dataclass
from enum import Enum
import threading
from concurrent.futures import ThreadPoolExecutor
from functools import reduce
from operator import xor

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/chaosbutterfly.log'),
        logging.StreamHandler()
    ]
)

class EncryptionMode(Enum):
    """åŠ å¯†æ¨¡å¼æšä¸¾"""
    FAST = "fast"
    STANDARD = "standard"
    SECURE = "secure"

@dataclass
class EncryptionConfig:
    """åŠ å¯†é…ç½®ç±»"""
    mode: EncryptionMode = EncryptionMode.STANDARD
    neural_hidden_size: int = 64
    neural_epochs: int = 50
    block_size: int = 8
    learning_rate: float = 0.01
    patience: int = 10
    validation_split: float = 0.2
    parallel_threads: int = 4
    
    def __post_init__(self):
        """æ ¹æ®æ¨¡å¼è‡ªåŠ¨è°ƒæ•´å‚æ•°"""
        if self.mode == EncryptionMode.FAST:
            self.neural_epochs = 20
            self.neural_hidden_size = 32
            self.block_size = 16
        elif self.mode == EncryptionMode.SECURE:
            self.neural_epochs = 200
            self.neural_hidden_size = 128
            self.block_size = 4
            self.patience = 50

class ConfigurableNeuralNetwork:
    """å¯é…ç½®çš„ç¥ç»ç½‘ç»œ"""
    
    def __init__(self, input_size: int, config: EncryptionConfig):
        self.input_size = input_size
        self.hidden_size = config.neural_hidden_size
        self.output_size = input_size
        self.learning_rate = config.learning_rate
        self.epochs = config.neural_epochs
        self.patience = config.patience
        self.validation_split = config.validation_split
        
        # Xavieråˆå§‹åŒ–
        self.weights_ih = np.random.normal(0, np.sqrt(2.0 / (input_size + self.hidden_size)), 
                                          (input_size, self.hidden_size))
        self.weights_ho = np.random.normal(0, np.sqrt(2.0 / (self.hidden_size + self.output_size)), 
                                          (self.hidden_size, self.output_size))
        self.bias_h = np.zeros((1, self.hidden_size))
        self.bias_o = np.zeros((1, self.output_size))
        
        # æ—©åœç›¸å…³
        self.best_val_loss = float('inf')
        self.patience_counter = 0
        self.loss_history = []
        
        self.logger = logging.getLogger('ConfigurableNeuralNetwork')
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))
    
    def forward(self, X):
        self.hidden = self.sigmoid(np.dot(X, self.weights_ih) + self.bias_h)
        self.output = self.sigmoid(np.dot(self.hidden, self.weights_ho) + self.bias_o)
        return self.output
    
    def backward(self, X, y, output):
        m = X.shape[0]
        
        output_error = y - output
        output_delta = output_error * output * (1 - output)
        
        hidden_error = output_delta.dot(self.weights_ho.T)
        hidden_delta = hidden_error * self.hidden * (1 - self.hidden)
        
        self.weights_ho += self.hidden.T.dot(output_delta) * self.learning_rate / m
        self.bias_o += np.sum(output_delta, axis=0, keepdims=True) * self.learning_rate / m
        self.weights_ih += X.T.dot(hidden_delta) * self.learning_rate / m
        self.bias_h += np.sum(hidden_delta, axis=0, keepdims=True) * self.learning_rate / m
    
    def adaptive_learning_rate(self, epoch: int, initial_loss: float, current_loss: float) -> float:
        """è‡ªé€‚åº”å­¦ä¹ ç‡è°ƒæ•´"""
        if epoch == 0:
            return self.learning_rate
        
        # å­¦ä¹ ç‡è¡°å‡
        decay_factor = 0.95
        adaptive_rate = self.learning_rate * (decay_factor ** (epoch // 10))
        
        # å¦‚æœæŸå¤±ä¸ä¸‹é™ï¼Œå¢åŠ å­¦ä¹ ç‡
        if len(self.loss_history) > 1 and current_loss > self.loss_history[-2]['train']:
            adaptive_rate *= 1.1
        
        return max(adaptive_rate, self.learning_rate * 0.1)  # æœ€å°å­¦ä¹ ç‡
    
    def train_with_validation(self, X: np.ndarray, validation_split: float = 0.2) -> np.ndarray:
        """å¸¦éªŒè¯çš„è®­ç»ƒ"""
        X = np.array(X).reshape(-1, 1)
        
        # æ•°æ®åˆ†å‰²
        split_idx = int(len(X) * (1 - validation_split))
        X_train, X_val = X[:split_idx], X[split_idx:]
        
        self.logger.info(f"å¼€å§‹ç¥ç»ç½‘ç»œè®­ç»ƒ (è®­ç»ƒæ ·æœ¬: {len(X_train)}, éªŒè¯æ ·æœ¬: {len(X_val)})")
        
        for epoch in range(self.epochs):
            # è®­ç»ƒ
            train_output = self.forward(X_train)
            train_loss = np.mean((X_train - train_output) ** 2)
            self.backward(X_train, X_train, train_output)
            
            # éªŒè¯
            val_output = self.forward(X_val)
            val_loss = np.mean((X_val - val_output) ** 2)
            
            # è®°å½•æŸå¤±
            self.loss_history.append({'train': train_loss, 'val': val_loss})
            
            # è‡ªé€‚åº”å­¦ä¹ ç‡
            if epoch > 0:
                self.learning_rate = self.adaptive_learning_rate(epoch, self.loss_history[0]['train'], train_loss)
            
            # æ—©åœæ£€æŸ¥
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.patience_counter = 0
            else:
                self.patience_counter += 1
                if self.patience_counter >= self.patience:
                    self.logger.info(f"è®­ç»ƒåœ¨ç¬¬ {epoch + 1} è½®æ”¶æ•›")
                    break
        
        return self.forward(X).flatten()

class AdvancedLorenzSystem:
    """é«˜çº§Lorenzæ··æ²Œç³»ç»Ÿ"""
    
    def __init__(self, x0: float, y0: float, z0: float, config: EncryptionConfig):
        self.x0, self.y0, self.z0 = x0, y0, z0
        self.sigma, self.rho, self.beta = 10.0, 28.0, 8.0/3.0
        self.dt = 0.01
        self.config = config
        self.logger = logging.getLogger('AdvancedLorenzSystem')
        
        # æ£€æŸ¥åˆå§‹æ¡ä»¶
        if abs(x0) > 50 or abs(y0) > 50 or abs(z0) > 50:
            self.logger.warning("åˆå§‹çŠ¶æ€å¯èƒ½è¶…å‡ºå…¸å‹æ··æ²ŒåŒºåŸŸ")
    
    def _lorenz_equations(self, state: np.ndarray) -> np.ndarray:
        """Lorenzæ–¹ç¨‹ç»„"""
        x, y, z = state
        dx = self.sigma * (y - x)
        dy = x * (self.rho - z) - y
        dz = x * y - self.beta * z
        return np.array([dx, dy, dz])
    
    def _runge_kutta_step(self, state: np.ndarray, dt: float) -> np.ndarray:
        """å››é˜¶Runge-Kuttaæ•°å€¼ç§¯åˆ†"""
        k1 = self._lorenz_equations(state)
        k2 = self._lorenz_equations(state + 0.5 * dt * k1)
        k3 = self._lorenz_equations(state + 0.5 * dt * k2)
        k4 = self._lorenz_equations(state + dt * k3)
        return state + (dt / 6.0) * (k1 + 2*k2 + 2*k3 + k4)
    
    def generate_sequence_chunk(self, start_state: np.ndarray, length: int) -> np.ndarray:
        """ç”Ÿæˆåºåˆ—å—"""
        sequence = np.zeros((length, 3))
        current_state = start_state.copy()
        
        for i in range(length):
            sequence[i] = current_state
            current_state = self._runge_kutta_step(current_state, self.dt)
        
        return sequence
    
    def generate_sequences_parallel(self, total_length: int) -> np.ndarray:
        """å¹¶è¡Œç”Ÿæˆæ··æ²Œåºåˆ—"""
        chunk_size = total_length // self.config.parallel_threads
        remainder = total_length % self.config.parallel_threads
        
        self.logger.info(f"ä½¿ç”¨ {self.config.parallel_threads} çº¿ç¨‹å¹¶è¡Œç”Ÿæˆ {total_length} ä¸ªæ··æ²Œç‚¹")
        
        # ä¸ºæ¯ä¸ªçº¿ç¨‹å‡†å¤‡ä¸åŒçš„åˆå§‹çŠ¶æ€
        initial_states = []
        base_state = np.array([self.x0, self.y0, self.z0])
        
        for i in range(self.config.parallel_threads):
            # è½»å¾®æ‰°åŠ¨åˆå§‹çŠ¶æ€ä»¥ç¡®ä¿ç‹¬ç«‹æ€§
            perturbed_state = base_state + np.random.normal(0, 0.01, 3)
            initial_states.append(perturbed_state)
        
        # å¹¶è¡Œæ‰§è¡Œ
        with ThreadPoolExecutor(max_workers=self.config.parallel_threads) as executor:
            futures = []
            for i in range(self.config.parallel_threads):
                length = chunk_size + (1 if i < remainder else 0)
                future = executor.submit(self.generate_sequence_chunk, initial_states[i], length)
                futures.append(future)
            
            # æ”¶é›†ç»“æœ
            sequences = []
            for future in futures:
                sequences.append(future.result())
        
        # åˆå¹¶åºåˆ—
        return np.vstack(sequences)

class AdvancedImageEncryption:
    """é«˜çº§å›¾åƒåŠ å¯†ç±»"""
    
    def __init__(self, config: EncryptionConfig = None):
        self.config = config or EncryptionConfig()
        self.logger = logging.getLogger('AdvancedImageEncryption')
        
        # ç¡®ä¿å¿…è¦ç›®å½•å­˜åœ¨
        os.makedirs('keys', exist_ok=True)
        os.makedirs('output', exist_ok=True)
    
    def _generate_initial_values_enhanced(self, image: np.ndarray) -> Tuple[float, float, float]:
        """å¢å¼ºçš„åˆå§‹å€¼ç”Ÿæˆ"""
        def enhanced_xor_sum(nums, offset):
            return reduce(xor, nums[offset:offset+16])
        
        # åŸºç¡€ç»Ÿè®¡ç‰¹å¾
        mean_val = np.mean(image)
        std_val = np.std(image)
        min_val, max_val = np.min(image), np.max(image)
        
        # å¤šå±‚å“ˆå¸Œ
        import hashlib
        combined_data = f"{mean_val:.6f}{std_val:.6f}{min_val}{max_val}".encode()
        hash_sha384 = hashlib.sha384(combined_data).digest()
        hash_sha256 = hashlib.sha256(combined_data).digest()
        
        # è½¬æ¢ä¸ºæ•°å€¼
        hash_nums = list(hash_sha384) + list(hash_sha256)
        
        # åŸºç¡€å€¼
        base_x = (hash_nums[0] + hash_nums[1] * 256) / 65535.0
        base_y = (hash_nums[2] + hash_nums[3] * 256) / 65535.0
        base_z = (hash_nums[4] + hash_nums[5] * 256) / 65535.0
          # å¢å¼ºè®¡ç®— - ä½¿ç”¨å®‰å…¨çš„æ•°å€¼è®¡ç®—é¿å…æº¢å‡º
        x0 = base_x + ((int(enhanced_xor_sum(hash_nums, 0)) + int(mean_val) + int(std_val)) % 256) / 256.0
        y0 = base_y + ((int(enhanced_xor_sum(hash_nums, 16)) + int(min_val) + int(max_val)) % 256) / 256.0  
        z0 = base_z + ((int(enhanced_xor_sum(hash_nums, 32)) + int(mean_val * std_val)) % 256) / 256.0
        
        return float(x0), float(y0), float(z0)
    
    def _encrypt_single_channel(self, image: np.ndarray) -> np.ndarray:
        """å•é€šé“åŠ å¯†"""
        # ç”Ÿæˆåˆå§‹å€¼
        x0, y0, z0 = self._generate_initial_values_enhanced(image)
        
        # ç”Ÿæˆæ··æ²Œåºåˆ—
        lorenz = AdvancedLorenzSystem(x0, y0, z0, self.config)
        M, N = image.shape
        
        # è®¡ç®—æ‰€éœ€åºåˆ—é•¿åº¦
        scramble_points_x = M  # è¡Œç½®ä¹±éœ€è¦Mä¸ªç‚¹
        scramble_points_y = N  # åˆ—ç½®ä¹±éœ€è¦Nä¸ªç‚¹
        scramble_points = scramble_points_x + scramble_points_y
        diffuse_points = ((M + self.config.block_size - 1) // self.config.block_size) * \
                        ((N + self.config.block_size - 1) // self.config.block_size) + \
                        self.config.block_size * self.config.block_size
        
        # ç”Ÿæˆåºåˆ—
        total_points = scramble_points + diffuse_points
        sequences = lorenz.generate_sequences_parallel(total_points)
        
        # åˆ†ç¦»åºåˆ—
        scramble_seq = sequences[:scramble_points]
        diffuse_seq = sequences[scramble_points:]
          # ç¥ç»ç½‘ç»œå¤„ç† - ä¿®å¤è¾“å…¥ç»´åº¦é—®é¢˜
        nn_scramble_x = ConfigurableNeuralNetwork(1, self.config)  # è¾“å…¥ç»´åº¦ä¸º1
        nn_scramble_y = ConfigurableNeuralNetwork(1, self.config)  # è¾“å…¥ç»´åº¦ä¸º1
        nn_diffuse = ConfigurableNeuralNetwork(1, self.config)     # è¾“å…¥ç»´åº¦ä¸º1
        
        x_seq = nn_scramble_x.train_with_validation(scramble_seq[:scramble_points_x, 0])
        y_seq = nn_scramble_y.train_with_validation(scramble_seq[scramble_points_x:scramble_points_x+scramble_points_y, 1])
        z_seq = nn_diffuse.train_with_validation(diffuse_seq[:, 2])
        
        # ä¿å­˜åºåˆ—å’Œå…ƒæ•°æ®
        self._save_encryption_data(x_seq, y_seq, z_seq, x0, y0, z0)
        
        # åŠ å¯†æ“ä½œ
        scrambled = self._scramble_image_optimized(image, x_seq, y_seq)
        result = self._diffuse_image_optimized(scrambled, z_seq)
        
        return result.astype(np.uint8)
    
    def _scramble_image_optimized(self, image: np.ndarray, x_seq: np.ndarray, y_seq: np.ndarray) -> np.ndarray:
        """ä¼˜åŒ–çš„å›¾åƒç½®ä¹±"""
        M, N = image.shape
        scrambled = image.copy()
        
        # é¢„è®¡ç®—ç´¢å¼•ä»¥æé«˜æ€§èƒ½
        x_indices = np.mod(np.floor(x_seq * 1e13), M).astype(int)
        y_indices = np.mod(np.floor(y_seq * 1e13), N).astype(int)
        
        # ç¡®ä¿ç´¢å¼•å”¯ä¸€æ€§
        x_indices = self._ensure_unique_indices(x_indices, M)
        y_indices = self._ensure_unique_indices(y_indices, N)
        
        # çŸ¢é‡åŒ–è¡Œç½®ä¹±
        for i in range(M//2):
            idx1, idx2 = x_indices[i], x_indices[M-i-1]
            if idx1 != idx2:
                scrambled[[idx1, idx2]] = scrambled[[idx2, idx1]]
        
        # çŸ¢é‡åŒ–åˆ—ç½®ä¹±
        for j in range(N//2):
            idx1, idx2 = y_indices[j], y_indices[N-j-1]
            if idx1 != idx2:
                scrambled[:, [idx1, idx2]] = scrambled[:, [idx2, idx1]]
        
        return scrambled
    
    def _diffuse_image_optimized(self, image: np.ndarray, z_seq: np.ndarray) -> np.ndarray:
        """ä¼˜åŒ–çš„å›¾åƒæ‰©æ•£"""
        M, N = image.shape
        diffused = image.copy().astype(int)
        
        # åˆ†å—å¤„ç†
        block_size = self.config.block_size
        seq_idx = 0
        
        for i in range(0, M, block_size):
            for j in range(0, N, block_size):
                # è®¡ç®—å®é™…å—å¤§å°
                actual_h = min(block_size, M - i)
                actual_w = min(block_size, N - j)
                
                # è·å–æ‰©æ•£å¯†é’¥
                if seq_idx < len(z_seq):
                    key = int(z_seq[seq_idx] * 255) % 256
                    seq_idx += 1
                else:
                    key = 128  # é»˜è®¤å€¼
                
                # æ‰©æ•£æ“ä½œ
                block = diffused[i:i+actual_h, j:j+actual_w]
                diffused[i:i+actual_h, j:j+actual_w] = (block + key) % 256
        
        return diffused.astype(np.uint8)
    
    def _ensure_unique_indices(self, indices: np.ndarray, max_val: int) -> np.ndarray:
        """ç¡®ä¿ç´¢å¼•å”¯ä¸€æ€§"""
        unique_indices = []
        used = set()
        
        for idx in indices:
            if idx not in used:
                unique_indices.append(idx)
                used.add(idx)
            else:
                # æ‰¾åˆ°æœªä½¿ç”¨çš„ç´¢å¼•
                for new_idx in range(max_val):
                    if new_idx not in used:
                        unique_indices.append(new_idx)
                        used.add(new_idx)
                        break
        
        return np.array(unique_indices)
    
    def _save_encryption_data(self, x_seq: np.ndarray, y_seq: np.ndarray, z_seq: np.ndarray, 
                             x0: float, y0: float, z0: float):
        """ä¿å­˜åŠ å¯†æ•°æ®"""
        np.savez_compressed('keys/encryption_data.npz',
                           x_seq=x_seq, y_seq=y_seq, z_seq=z_seq,
                           x0=x0, y0=y0, z0=z0,
                           config_mode=self.config.mode.value)
    
    def encrypt_with_progress(self, image: np.ndarray, progress_callback=None) -> np.ndarray:
        """å¸¦è¿›åº¦å›è°ƒçš„åŠ å¯†"""
        start_time = time.time()
        
        if progress_callback:
            progress_callback(0)
        
        if len(image.shape) == 3:
            # å½©è‰²å›¾åƒ
            result = np.zeros_like(image)
            for i in range(image.shape[2]):
                if progress_callback:
                    progress_callback(int((i / image.shape[2]) * 100))
                result[:, :, i] = self._encrypt_single_channel(image[:, :, i])
        else:
            # ç°åº¦å›¾åƒ
            result = self._encrypt_single_channel(image)
        
        if progress_callback:
            progress_callback(100)
        
        encryption_time = time.time() - start_time
        throughput = (image.nbytes / (1024 * 1024)) / encryption_time
        
        self.logger.info(f"åŠ å¯†å®Œæˆ - è€—æ—¶: {encryption_time:.3f}ç§’, ååé‡: {throughput:.2f} MB/s")
        
        return result

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºä¸‰ç§åŠ å¯†æ¨¡å¼"""
    print("ğŸš€ ChaosButterfly é«˜çº§åŠ å¯†ç³»ç»Ÿ")
    print("=" * 50)
    
    # åŠ è½½æµ‹è¯•å›¾åƒ
    img = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)
    if img is None:
        print("âŒ æ— æ³•åŠ è½½æµ‹è¯•å›¾åƒ lena.png")
        return
    
    def progress_callback(percent):
        print(f"\r  æ­£åœ¨åŠ å¯†ç°åº¦å›¾åƒ ({percent}%)", end="", flush=True)
    
    # æµ‹è¯•ä¸‰ç§æ¨¡å¼
    modes = [
        (EncryptionMode.FAST, "encrypted_fast.png"),
        (EncryptionMode.STANDARD, "encrypted_standard.png"),
        (EncryptionMode.SECURE, "encrypted_secure.png")
    ]
    
    for mode, output_file in modes:
        print(f"\nğŸ”„ æµ‹è¯• {mode.value.upper()} æ¨¡å¼...")
        
        config = EncryptionConfig(mode=mode)
        encryptor = AdvancedImageEncryption(config)
        
        start_time = time.time()
        encrypted = encryptor.encrypt_with_progress(img, progress_callback)
        encryption_time = time.time() - start_time
        
        # ä¿å­˜åŠ å¯†å›¾åƒ
        cv2.imwrite(f'output/{output_file}', encrypted)
        
        throughput = (img.nbytes / (1024 * 1024)) / encryption_time
        
        print(f"\n  âœ“ åŠ å¯†å®Œæˆ: output/{output_file}")
        print(f"  â±ï¸  è€—æ—¶: {encryption_time:.3f}ç§’")
        print(f"  ğŸ“Š ååé‡: {throughput:.2f} MB/s")

if __name__ == "__main__":
    main()
