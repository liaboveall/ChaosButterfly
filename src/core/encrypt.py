import numpy as np
import cv2
from hashlib import sha384
from functools import reduce
from operator import xor
import time
import os

class OptimizedNeuralNetwork:
    """
    ä¼˜åŒ–ç‰ˆç¥ç»ç½‘ç»œç±» - å¢åŠ äº†æ—©åœå’Œæ‰¹å¤„ç†
    """
    def __init__(self, sequence_length, hidden_size=10, learning_rate=0.6):
        self.learning_rate = learning_rate
        self.hidden_size = hidden_size
        self.sequence_length = sequence_length
        self.a = 0.35
        
        # ä½¿ç”¨æ›´å¥½çš„æƒé‡åˆå§‹åŒ–ï¼ˆXavieråˆå§‹åŒ–ï¼‰
        fan_in = 1
        fan_out = hidden_size
        limit = np.sqrt(6 / (fan_in + fan_out))
        self.Ve = np.random.uniform(-limit, limit, (1, hidden_size))
        self.Ws = np.random.uniform(-limit, limit, (hidden_size, 1))
        self.V0e = np.zeros((1, hidden_size))
        self.W0s = np.zeros((1, 1))
        
        # è®­ç»ƒå†å²è®°å½•
        self.loss_history = []
    
    def tanh(self, x):
        """ä¼˜åŒ–çš„tanhå‡½æ•° - é˜²æ­¢æ•°å€¼æº¢å‡º"""
        return np.tanh(np.clip(x, -500, 500))
    
    def tanh_derivative(self, x):
        """ä¼˜åŒ–çš„tanhå¯¼æ•°"""
        tanh_x = self.tanh(x)
        return 1.0 - tanh_x**2
    
    def train(self, X, epochs=100, early_stopping_patience=10):
        """ä¼˜åŒ–çš„è®­ç»ƒè¿‡ç¨‹ - å¢åŠ æ—©åœæœºåˆ¶"""
        X = np.array(X).reshape(-1, 1)
        tolerance = 1e-6
        best_loss = float('inf')
        patience_counter = 0
        
        for epoch in range(epochs):
            # å‰å‘ä¼ æ’­
            hidden = self.tanh(np.dot(X, self.Ve) + self.V0e)
            output = self.a * (np.dot(hidden, self.Ws) + self.W0s)
            
            # æŸå¤±è®¡ç®—
            error = output - X
            current_loss = np.mean(error**2)  # MSEæŸå¤±
            self.loss_history.append(current_loss)
            
            # æ—©åœæ£€æŸ¥
            if current_loss < best_loss - tolerance:
                best_loss = current_loss
                patience_counter = 0
            else:
                patience_counter += 1
                if patience_counter >= early_stopping_patience:
                    break
            
            # åå‘ä¼ æ’­ï¼ˆå‘é‡åŒ–å®ç°ï¼‰
            delta_output = 2 * self.a * error / len(X)  # MSEæ¢¯åº¦
            delta_hidden = np.multiply(
                self.tanh_derivative(hidden),
                np.dot(delta_output, self.Ws.T)
            )
            
            # æƒé‡æ›´æ–°
            self.Ws -= self.learning_rate * np.dot(hidden.T, delta_output)
            self.W0s -= self.learning_rate * np.mean(delta_output, axis=0, keepdims=True)
            self.Ve -= self.learning_rate * np.dot(X.T, delta_hidden)
            self.V0e -= self.learning_rate * np.mean(delta_hidden, axis=0, keepdims=True)
        
        # ç”Ÿæˆæœ€ç»ˆåºåˆ—
        hidden = self.tanh(np.dot(X, self.Ve) + self.V0e)
        return (self.a * (np.dot(hidden, self.Ws) + self.W0s)).flatten()

class OptimizedLorenzSystem:
    """
    ä¼˜åŒ–ç‰ˆLorenzç³»ç»Ÿ - æ”¯æŒæ‰¹é‡ç”Ÿæˆå’Œæ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
    """
    def __init__(self, x0, y0, z0):
        self.reset(x0, y0, z0)
        self.a = 10.0
        self.b = 40.0
        self.c = 2.5
        self.dt = 0.005
        
    def reset(self, x0, y0, z0):
        """é‡ç½®ç³»ç»ŸçŠ¶æ€"""
        self.x = x0
        self.y = y0
        self.z = z0
        
    def next_point(self):
        """è®¡ç®—ä¸‹ä¸€ä¸ªç‚¹ - å¢åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥"""
        dt = self.dt
        a, b, c = self.a, self.b, self.c
        x, y, z = self.x, self.y, self.z

        # é˜²æ­¢æ•°å€¼æº¢å‡º
        xy_product = np.clip(x * y, -100, 100)
        exp_term = np.clip(0.01 * np.exp(xy_product), 0, 1e6)

        dx = a * (y - x)
        dy = b * x - x * z + y
        dz = 200 * x * x + exp_term - c * z

        self.x += dx * dt
        self.y += dy * dt
        self.z += dz * dt

        # é˜²æ­¢ç³»ç»Ÿå‘æ•£
        if abs(self.x) > 1e6 or abs(self.y) > 1e6 or abs(self.z) > 1e6:
            self.x, self.y, self.z = np.random.uniform(-1, 1, 3)

        return self.x, self.y, self.z

    def generate_sequences_batch(self, num_points, warmup=1000):
        """æ‰¹é‡ç”Ÿæˆåºåˆ— - æ›´é«˜æ•ˆçš„å®ç°"""
        # é¢„çƒ­
        for _ in range(warmup):
            self.next_point()
        
        # æ‰¹é‡ç”Ÿæˆ
        sequences = np.zeros((num_points, 3))
        for i in range(num_points):
            sequences[i] = self.next_point()
        
        # å‘é‡åŒ–å½’ä¸€åŒ–
        min_vals = np.min(sequences, axis=0)
        max_vals = np.max(sequences, axis=0)
        
        # é˜²æ­¢é™¤é›¶
        ranges = max_vals - min_vals
        ranges[ranges == 0] = 1.0
        
        sequences = (sequences - min_vals) / ranges
        return sequences

class SecurityAnalyzer:
    """
    å®‰å…¨æ€§åˆ†æå·¥å…·ç±»
    """
    @staticmethod
    def calculate_entropy(image):
        """è®¡ç®—å›¾åƒä¿¡æ¯ç†µ"""
        hist = cv2.calcHist([image], [0], None, [256], [0, 256])
        prob = hist / image.size
        prob = prob[prob > 0]  # ç§»é™¤é›¶æ¦‚ç‡
        return -np.sum(prob * np.log2(prob))
    
    @staticmethod
    def calculate_correlation(image1, image2):
        """è®¡ç®—ä¸¤å›¾åƒç›¸å…³æ€§"""
        return np.corrcoef(image1.flatten(), image2.flatten())[0, 1]
    
    @staticmethod
    def calculate_pixel_change_rate(image1, image2):
        """è®¡ç®—åƒç´ å˜åŒ–ç‡"""
        return np.sum(image1 != image2) / image1.size * 100
    
    @staticmethod
    def analyze_histogram_uniformity(image):
        """åˆ†æç›´æ–¹å›¾å‡åŒ€æ€§"""
        hist = cv2.calcHist([image], [0], None, [256], [0, 256]).flatten()
        expected = image.size / 256  # ç†æƒ³å‡åŒ€åˆ†å¸ƒ
        chi_square = np.sum((hist - expected)**2 / expected)
        return chi_square
    
    @staticmethod
    def full_security_analysis(original, encrypted, decrypted=None):
        """å®Œæ•´å®‰å…¨æ€§åˆ†æ"""
        analysis = {
            'original_entropy': SecurityAnalyzer.calculate_entropy(original),
            'encrypted_entropy': SecurityAnalyzer.calculate_entropy(encrypted),
            'correlation': SecurityAnalyzer.calculate_correlation(original, encrypted),
            'pixel_change_rate': SecurityAnalyzer.calculate_pixel_change_rate(original, encrypted),
            'histogram_uniformity': SecurityAnalyzer.analyze_histogram_uniformity(encrypted)
        }
        
        if decrypted is not None:
            analysis['decryption_mse'] = np.mean((original - decrypted)**2)
            analysis['decryption_success'] = analysis['decryption_mse'] < 1.0
        
        return analysis

class OptimizedImageEncryption:
    """
    ä¼˜åŒ–ç‰ˆå›¾åƒåŠ å¯†ç±»
    """
    def __init__(self, block_size=8, base_x=0.12, base_y=0.23, base_z=0.34):
        self.block_size = block_size
        self.base_x = base_x
        self.base_y = base_y
        self.base_z = base_z
        self.security_analyzer = SecurityAnalyzer()
        
    def generate_initial_values(self, image):
        """ä¼˜åŒ–çš„åˆå§‹å€¼ç”Ÿæˆ - å¢åŠ æ›´å¤šç†µæº"""
        # ä½¿ç”¨å¤šç§å“ˆå¸Œå¢å¼ºå®‰å…¨æ€§
        hash_val = sha384(image.tobytes()).digest()
        hash_nums = np.frombuffer(hash_val, dtype=np.uint8)
        
        # æ·»åŠ å›¾åƒç»Ÿè®¡ç‰¹å¾ä½œä¸ºé¢å¤–ç†µæº
        mean_val = np.mean(hash_nums)
        std_val = np.std(image.astype(np.float64))
        skew_val = np.mean((image - np.mean(image))**3)
        
        def xor_sum(nums):
            return reduce(xor, nums)
        
        # å¢å¼ºçš„åˆå§‹å€¼è®¡ç®—
        entropy_factor = (std_val + abs(skew_val)) % 256
        x0 = self.base_x + ((xor_sum(hash_nums[:8]) + mean_val + entropy_factor) % 256) / 256
        y0 = self.base_y + ((xor_sum(hash_nums[8:16]) + mean_val + entropy_factor) % 256) / 256
        z0 = self.base_z + ((xor_sum(hash_nums[16:24]) + mean_val + entropy_factor) % 256) / 256
        
        # ä¿å­˜å¯†é’¥ä¿¡æ¯
        os.makedirs("keys", exist_ok=True)
        with open("keys/initial_values.txt", "w") as f:
            f.write(f"x0: {x0}\n")
            f.write(f"y0: {y0}\n")
            f.write(f"z0: {z0}\n")
            f.write(f"entropy_factor: {entropy_factor}\n")
        
        return x0, y0, z0

    def scramble_image_optimized(self, image, x_seq, y_seq):
        """ä¼˜åŒ–çš„åƒç´ ç½®ä¹± - ä½¿ç”¨æ›´å®‰å…¨çš„ç½®ä¹±ç®—æ³•"""
        M, N = image.shape
        scrambled = image.copy()
        
        # å¢å¼ºçš„è¡Œç½®ä¹±
        if len(x_seq) >= M:
            row_indices = np.argsort(x_seq[:M])
            scrambled = scrambled[row_indices, :]
        
        # å¢å¼ºçš„åˆ—ç½®ä¹±
        if len(y_seq) >= N:
            col_indices = np.argsort(y_seq[:N])
            scrambled = scrambled[:, col_indices]
        
        return scrambled

    def diffuse_image_optimized(self, image, sequence):
        """ä¼˜åŒ–çš„åƒç´ æ‰©æ•£ - å¢å¼ºå®‰å…¨æ€§"""
        M, N = image.shape
        S, T = self.block_size, self.block_size
        
        # è‡ªé€‚åº”å¡«å……
        pad_rows = (S - M % S) % S
        pad_cols = (T - N % T) % T
        padded = np.pad(image, ((0, pad_rows), (0, pad_cols)), mode='reflect')
        
        # åˆ†å—å¤„ç†
        blocks = []
        for i in range(0, padded.shape[0], S):
            for j in range(0, padded.shape[1], T):
                block = padded[i:i+S, j:j+T].astype(np.uint8)
                blocks.append(block)
        
        num_blocks = len(blocks)
        if len(sequence) < num_blocks + S*T:
            raise ValueError("åºåˆ—é•¿åº¦ä¸è¶³")
        
        # ç”Ÿæˆç½®æ¢åºåˆ—
        U = sequence[:num_blocks]
        V = np.argsort(U)
        
        # ç”Ÿæˆæ‰©æ•£åºåˆ—
        E = np.mod(np.floor(sequence[num_blocks:num_blocks+S*T] * 1e13), 256).astype(np.uint8)
        E = E.reshape(S, T)
        
        # å¢å¼ºçš„æ‰©æ•£æ“ä½œ
        diffused_blocks = [None] * num_blocks
        for i in range(num_blocks):
            original_pos = V[i]
            Q = blocks[original_pos]
            
            if i == 0:
                Q_diffused = np.bitwise_xor(Q, E)
            else:
                # ä½¿ç”¨å¤šé‡å¼‚æˆ–å¢å¼ºå®‰å…¨æ€§
                prev_block = diffused_blocks[i-1]
                mask = np.mod(np.floor(sequence[num_blocks+S*T+i] * 1e13), 256).astype(np.uint8)
                Q_diffused = np.bitwise_xor(np.bitwise_xor(Q, prev_block), mask)
                
            diffused_blocks[i] = Q_diffused
        
        # é‡æ„å›¾åƒ
        final_blocks = [None] * num_blocks
        for i in range(num_blocks):
            final_blocks[V[i]] = diffused_blocks[i]
        
        rows = (padded.shape[0] // S)
        cols = (padded.shape[1] // T)
        diffused = np.zeros_like(padded)
        
        for idx, block in enumerate(final_blocks):
            i = (idx // cols) * S
            j = (idx % cols) * T
            diffused[i:i+S, j:j+T] = block
        
        return diffused[:M, :N]

    def encrypt(self, image, save_analysis=True):
        """ä¼˜åŒ–çš„åŠ å¯†ä¸»å‡½æ•°"""
        start_time = time.time()
        
        if len(image.shape) == 3:
            encrypted_channels = []
            for channel in cv2.split(image):
                encrypted_channel = self.encrypt(channel, save_analysis=False)
                encrypted_channels.append(encrypted_channel)
            result = cv2.merge(encrypted_channels)
        else:
            # ç”Ÿæˆåˆå§‹å€¼
            x0, y0, z0 = self.generate_initial_values(image)
            
            # ä½¿ç”¨ä¼˜åŒ–çš„Lorenzç³»ç»Ÿ
            lorenz = OptimizedLorenzSystem(x0, y0, z0)
            M, N = image.shape
            
            # è®¡ç®—æ‰€éœ€åºåˆ—é•¿åº¦
            scramble_points = max(M, N)
            block_count = ((M + self.block_size - 1) // self.block_size) * \
                         ((N + self.block_size - 1) // self.block_size)
            diffuse_points = block_count + self.block_size * self.block_size + block_count
            
            # ç”Ÿæˆæ··æ²Œåºåˆ—
            total_points = max(scramble_points, diffuse_points)
            chaos_seq = lorenz.generate_sequences_batch(total_points)
            
            # ä½¿ç”¨ä¼˜åŒ–çš„ç¥ç»ç½‘ç»œ
            nn = OptimizedNeuralNetwork(sequence_length=total_points)
            
            x_seq = nn.train(chaos_seq[:scramble_points, 0])
            y_seq = nn.train(chaos_seq[:scramble_points, 1])
            z_seq = nn.train(chaos_seq[:diffuse_points, 2])
            
            # ä¿å­˜åºåˆ—
            os.makedirs("keys", exist_ok=True)
            np.savez('keys/sequences.npz', 
                    x_seq=x_seq, y_seq=y_seq, z_seq=z_seq,
                    M=M, N=N, block_size=self.block_size)
              # åŠ å¯†è¿‡ç¨‹
            scrambled = self.scramble_image_optimized(image, x_seq, y_seq)
            result = self.diffuse_image_optimized(scrambled, z_seq)
        
        encryption_time = time.time() - start_time
        
        # å®‰å…¨æ€§åˆ†æ
        if save_analysis:
            analysis = self.security_analyzer.full_security_analysis(image, result)
            analysis['encryption_time'] = encryption_time
            
            with open("keys/security_analysis.txt", "w", encoding='utf-8') as f:
                f.write("=== ChaosButterfly å®‰å…¨æ€§åˆ†ææŠ¥å‘Š ===\n")
                f.write(f"åŸå§‹å›¾åƒç†µ: {analysis['original_entropy']:.4f}\n")
                f.write(f"åŠ å¯†å›¾åƒç†µ: {analysis['encrypted_entropy']:.4f}\n")
                f.write(f"ç›¸å…³æ€§: {analysis['correlation']:.6f}\n")
                f.write(f"åƒç´ å˜åŒ–ç‡: {analysis['pixel_change_rate']:.2f}%\n")
                f.write(f"ç›´æ–¹å›¾å‡åŒ€æ€§(chi-square): {analysis['histogram_uniformity']:.2f}\n")
                f.write(f"åŠ å¯†è€—æ—¶: {encryption_time:.4f}ç§’\n")
        
        return result.astype(np.uint8)

# æµ‹è¯•å‡½æ•°
def test_optimization():
    """æµ‹è¯•ä¼˜åŒ–æ•ˆæœ"""
    print("ğŸ§ª æµ‹è¯•ä¼˜åŒ–ç‰ˆåŠ å¯†ç³»ç»Ÿ...")
    
    # è¯»å–æµ‹è¯•å›¾åƒ
    img = cv2.imread('lena.png', cv2.IMREAD_GRAYSCALE)
    if img is None:
        print("âŒ æµ‹è¯•å›¾åƒæœªæ‰¾åˆ°")
        return
    
    # åˆ›å»ºä¼˜åŒ–ç‰ˆåŠ å¯†å™¨
    encryptor = OptimizedImageEncryption()
    
    # åŠ å¯†æµ‹è¯•
    start_time = time.time()
    encrypted = encryptor.encrypt(img)
    encryption_time = time.time() - start_time
    
    # ä¿å­˜ç»“æœ
    os.makedirs("output", exist_ok=True)
    cv2.imwrite('output/encrypted_optimized.png', encrypted)
    
    print(f"âœ… ä¼˜åŒ–ç‰ˆåŠ å¯†å®Œæˆï¼Œè€—æ—¶: {encryption_time:.4f}ç§’")
    print("ğŸ“Š å®‰å…¨æ€§åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ° keys/security_analysis.txt")

if __name__ == "__main__":
    test_optimization()
